{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Result</th>\n",
       "      <th>Hour</th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>Opening</th>\n",
       "      <th>TimeControl</th>\n",
       "      <th>Termination</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1512</td>\n",
       "      <td>1570</td>\n",
       "      <td>28072</td>\n",
       "      <td>1074584</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>328</td>\n",
       "      <td>75</td>\n",
       "      <td>137</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>163</td>\n",
       "      <td>328</td>\n",
       "      <td>81</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>457</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1465</td>\n",
       "      <td>1436</td>\n",
       "      <td>595</td>\n",
       "      <td>1074584</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>270</td>\n",
       "      <td>462</td>\n",
       "      <td>110</td>\n",
       "      <td>462</td>\n",
       "      <td>311</td>\n",
       "      <td>116</td>\n",
       "      <td>739</td>\n",
       "      <td>169</td>\n",
       "      <td>128</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1665</td>\n",
       "      <td>1765</td>\n",
       "      <td>34752</td>\n",
       "      <td>1074584</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>183</td>\n",
       "      <td>320</td>\n",
       "      <td>649</td>\n",
       "      <td>181</td>\n",
       "      <td>350</td>\n",
       "      <td>166</td>\n",
       "      <td>172</td>\n",
       "      <td>376</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1377</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1595</td>\n",
       "      <td>1673</td>\n",
       "      <td>11136</td>\n",
       "      <td>47338</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>279</td>\n",
       "      <td>84</td>\n",
       "      <td>101</td>\n",
       "      <td>333</td>\n",
       "      <td>88</td>\n",
       "      <td>105</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1511</td>\n",
       "      <td>1621</td>\n",
       "      <td>48705</td>\n",
       "      <td>105090</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>81</td>\n",
       "      <td>243</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>191</td>\n",
       "      <td>360</td>\n",
       "      <td>88</td>\n",
       "      <td>243</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event  White  Black  Result  Hour  WhiteElo  BlackElo  Opening  \\\n",
       "0      1    123     62       2    22      1512      1570    28072   \n",
       "1      1    457     66       2    22      1465      1436      595   \n",
       "2      0     44    216       2    22      1665      1765    34752   \n",
       "3      2     35   1377       2    22      1595      1673    11136   \n",
       "4      4     44    187       2    22      1511      1621    48705   \n",
       "\n",
       "   TimeControl  Termination  ...  581  582  583  584  585  586  587  588  589  \\\n",
       "0      1074584            1  ...  163  328   75  137   82   77  163  328   81   \n",
       "1      1074584            1  ...  270  462  110  462  311  116  739  169  128   \n",
       "2      1074584            1  ...   94  183  320  649  181  350  166  172  376   \n",
       "3        47338            1  ...  333   81  105  279   84  101  333   88  105   \n",
       "4       105090            1  ...  479   81  243   90   84  191  360   88  243   \n",
       "\n",
       "   590  \n",
       "0  137  \n",
       "1   99  \n",
       "2  677  \n",
       "3  279  \n",
       "4  452  \n",
       "\n",
       "[5 rows x 602 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"C:/Users/franc/Documents/Lic. IA/Semestre 4/Machine learning\" # Cambiar por la ruta de los datos\n",
    "df = pd.read_csv(path + '/data/chess_games_clean2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 716289 entries, 0 to 716288\n",
      "Columns: 602 entries, Event to 590\n",
      "dtypes: int64(601), object(1)\n",
      "memory usage: 3.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Event', 'White', 'Black', 'Hour', 'WhiteElo', 'BlackElo', 'Opening','TimeControl', 'Termination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de modelos a probar\n",
    "models = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(max_depth=10),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando modelos para datos sin \"AN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[columnas]\n",
    "y = df['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)\n",
    "\n",
    "#preprocesamiento\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Train: \n",
      "Accuracy: 0.3980116258980753\n",
      "Precision: 0.42461736546625706\n",
      "Recall: 0.3980116258980753\n",
      "F1 Score: 0.3649413228351222\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.3967945943682028\n",
      "Precision: 0.4246339456830236\n",
      "Recall: 0.3967945943682028\n",
      "F1 Score: 0.36409761697088044\n",
      "\n",
      "RandomForestClassifier\n",
      "Train: \n",
      "Accuracy: 0.48170343314759584\n",
      "Precision: 0.4859675838782772\n",
      "Recall: 0.48170343314759584\n",
      "F1 Score: 0.48251816246909945\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.4711988161219618\n",
      "Precision: 0.475738870150794\n",
      "Recall: 0.4711988161219618\n",
      "F1 Score: 0.47204419519087315\n",
      "\n",
      "LogisticRegression\n",
      "Train: \n",
      "Accuracy: 0.466812441211732\n",
      "Precision: 0.4661146597471084\n",
      "Recall: 0.466812441211732\n",
      "F1 Score: 0.4664040848320996\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.46688492091192113\n",
      "Precision: 0.46639159230605237\n",
      "Recall: 0.46688492091192113\n",
      "F1 Score: 0.4666120262146213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print(model_name)\n",
    "    print(\"Train: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_pred_train)}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print(f\"F1 Score: {f1_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print()\n",
    "    print(\"Test: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando modelos solo para AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Result', 'AN'])\n",
    "X = X.drop(columns = columnas)\n",
    "y = df['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Train: \n",
      "Accuracy: 0.6553641949562938\n",
      "Precision: 0.6543970651151966\n",
      "Recall: 0.6553641949562938\n",
      "F1 Score: 0.6540173545772165\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.6561029750520041\n",
      "Precision: 0.6550177032781399\n",
      "Recall: 0.6561029750520041\n",
      "F1 Score: 0.6548144652146877\n",
      "\n",
      "RandomForestClassifier\n",
      "Train: \n",
      "Accuracy: 0.7135442934151904\n",
      "Precision: 0.7169282816176804\n",
      "Recall: 0.7135442934151904\n",
      "F1 Score: 0.7122928757122269\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.7091192114925519\n",
      "Precision: 0.7122153622159101\n",
      "Recall: 0.7091192114925519\n",
      "F1 Score: 0.7078557076917102\n",
      "\n",
      "LogisticRegression\n",
      "Train: \n",
      "Accuracy: 0.6859733592074425\n",
      "Precision: 0.6931447296516045\n",
      "Recall: 0.6859733592074425\n",
      "F1 Score: 0.6846638803635141\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.6848622764522749\n",
      "Precision: 0.6917586693297378\n",
      "Recall: 0.6848622764522749\n",
      "F1 Score: 0.6834644162600778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print(model_name)\n",
    "    print(\"Train: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_pred_train)}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print(f\"F1 Score: {f1_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print()\n",
    "    print(\"Test: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando todas las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(max_depth=10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Result', 'AN'])\n",
    "y = df['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Train: \n",
      "Accuracy: 0.6697770277698764\n",
      "Precision: 0.676823893955739\n",
      "Recall: 0.6697770277698764\n",
      "F1 Score: 0.6674194315931412\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.670496586578062\n",
      "Precision: 0.6774442600370281\n",
      "Recall: 0.670496586578062\n",
      "F1 Score: 0.6681076860181462\n",
      "\n",
      "RandomForestClassifier\n",
      "Train: \n",
      "Accuracy: 0.7332692297624387\n",
      "Precision: 0.7330709331911709\n",
      "Recall: 0.7332692297624387\n",
      "F1 Score: 0.7324512401429868\n",
      "\n",
      "Test: \n",
      "Accuracy: 0.727359030560248\n",
      "Precision: 0.7270820566816834\n",
      "Recall: 0.727359030560248\n",
      "F1 Score: 0.7265473816644827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print(model_name)\n",
    "    print(\"Train: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_pred_train)}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print(f\"F1 Score: {f1_score(y_train, y_pred_train, average='weighted')}\")\n",
    "    print()\n",
    "    print(\"Test: \")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred_test, average='weighted')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch para RandomForest (no se terminó de entrenar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Result', 'AN'])\n",
    "y = df['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV para RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_depth': [10, 100],\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "|Modelo| sin AN|con AN| todas|\n",
    "|------|-------|------|------|\n",
    "|MultinomialNB| 0.39|0.65|0.67|\n",
    "|RandomForest|0.48|0.70| 0.72|\n",
    "|Logistic| 0.46|0.68| |\n",
    "|RRN|0.33|0.36| |\n",
    "|LSTM| | | 0.73|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando redes neuronales\n",
    "### Columnas sin AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[columnas]\n",
    "y = df['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 997us/step - accuracy: 0.3324 - loss: 616.7380 - val_accuracy: 0.3345 - val_loss: -897.7373\n",
      "Epoch 2/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 946us/step - accuracy: 0.3345 - loss: -6010.7974 - val_accuracy: 0.3345 - val_loss: -24556.5820\n",
      "Epoch 3/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 942us/step - accuracy: 0.3334 - loss: -45965.4375 - val_accuracy: 0.3345 - val_loss: -32977.7305\n",
      "Epoch 4/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - accuracy: 0.3326 - loss: -220736.3125 - val_accuracy: 0.3345 - val_loss: -295390.4375\n",
      "Epoch 5/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 910us/step - accuracy: 0.3317 - loss: -588816.3750 - val_accuracy: 0.3345 - val_loss: -615976.1250\n",
      "Epoch 6/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 949us/step - accuracy: 0.3330 - loss: -1121869.8750 - val_accuracy: 0.3345 - val_loss: -1550724.1250\n",
      "Epoch 7/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 926us/step - accuracy: 0.3341 - loss: -2373554.5000 - val_accuracy: 0.3345 - val_loss: -2288110.5000\n",
      "Epoch 8/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 923us/step - accuracy: 0.3328 - loss: -3748479.0000 - val_accuracy: 0.3345 - val_loss: -2228235.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - accuracy: 0.3330 - loss: -7151972.0000 - val_accuracy: 0.3345 - val_loss: -6995973.5000\n",
      "Epoch 10/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.3333 - loss: -11358516.0000 - val_accuracy: 0.3345 - val_loss: -10796171.0000\n",
      "\u001b[1m4477/4477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 586us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1] , activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4477/4477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 526us/step\n",
      "Accuracy: 0.33496209635762053\n",
      "Precision: 0.11219960599629186\n",
      "Recall: 0.33496209635762053\n",
      "F1 Score: 0.16809406994014747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [np.argmax(pred) for pred in y_pred]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sólo columnas AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Result', 'AN'])\n",
    "X = X.drop(columns = columnas)\n",
    "y = df['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - accuracy: 0.3632 - loss: -395232992.0000 - val_accuracy: 0.3660 - val_loss: -4748882944.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1ms/step - accuracy: 0.3619 - loss: -9247850496.0000 - val_accuracy: 0.3649 - val_loss: -29164484608.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - accuracy: 0.3621 - loss: -41646186496.0000 - val_accuracy: 0.3647 - val_loss: -87457529856.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - accuracy: 0.3634 - loss: -112984662016.0000 - val_accuracy: 0.3665 - val_loss: -193378091008.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.3644 - loss: -234191175680.0000 - val_accuracy: 0.3650 - val_loss: -361520300032.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.3633 - loss: -426884759552.0000 - val_accuracy: 0.3650 - val_loss: -604534538240.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - accuracy: 0.3642 - loss: -698608320512.0000 - val_accuracy: 0.3662 - val_loss: -936724529152.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - accuracy: 0.3649 - loss: -1054327439360.0000 - val_accuracy: 0.3661 - val_loss: -1372150038528.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.3645 - loss: -1522794889216.0000 - val_accuracy: 0.3649 - val_loss: -1923206217728.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m17908/17908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - accuracy: 0.3643 - loss: -2126248935424.0000 - val_accuracy: 0.3649 - val_loss: -2604391202816.0000\n",
      "\u001b[1m4477/4477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 663us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1] , activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sample(6000)\n",
    "\n",
    "X = df1.drop(columns=['Result', 'AN'])\n",
    "X = X.drop(columns = columnas)\n",
    "y = df1['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.4762 - loss: 1.0738 - val_accuracy: 0.7139 - val_loss: 0.7025\n",
      "Epoch 2/2\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.7794 - loss: 0.5531 - val_accuracy: 0.7333 - val_loss: 0.6226\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7470 - loss: 0.6055\n",
      "Accuracy: 0.7333333492279053\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim= X_train.max().max() + 1, output_dim=128, input_length=1))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(units=4, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate=0.01) \n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algún momento sí se entrenaba relativamente rápido pero después cada época tardaba en entrenarse 2 horas. El siguiente resultado es de un modelo que se entrenó en media hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 99ms/step\n",
      "Accuracy: 0.7333333333333333\n",
      "Precision: 0.734690238361736\n",
      "Recall: 0.7333333333333333\n",
      "F1 Score: 0.7337665055383706\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#matriz de confusion y metricas\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [np.argmax(pred) for pred in y_pred]\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
